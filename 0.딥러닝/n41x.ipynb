{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled3.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "maUCYpOVTN1G"
      },
      "source": [
        "# N411. 신경망과 퍼셉트론\n",
        " "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NX2fdSc8TvSt"
      },
      "source": [
        "딥러닝의 기초<br/>\n",
        "딥러닝이란 인간의 신경망을 모방해서 만든 학습 구조이다.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "scMkEMjKTby3"
      },
      "source": [
        "## [] Perceptron <br/><br/>\n",
        "신경망의 가장 기초단위로 퍼셉트론이 있는데 퍼셉트론이란 다수의 신호를 받아서 뉴런과 뉴런사이의 가중치와 바이어스를 가지고 계산해 하나의 출력을 만드는 것이라고 설명할 수 있다.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RlEpNIb57zHv"
      },
      "source": [
        "<img src=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FnMnxQ%2FbtqEu6nEvJ4%2FkkshogxDJUjgLuswOwjGq0%2Fimg.png\" alt=\"Gradient Descent in 1D\" width=\"400\"/>\n",
        "\n",
        "X1,X2는 입력만을 받는 입력 뉴런을 의미한다.<br/>\n",
        "화살표 W1,W2는 가중치를 의미한다. 가중치란 입력된 값에 대해서 얼마나 더 중요한지를 비중을 제어하는 파라미터라고 볼 수 있다. 가중치가 크면 더 강한 신호를 흘려보낸다.<br/>\n",
        "b는 편향으로 편향은 입력신호와 가중치를 곱한후 다 더한 가중합에 마지막으로 더해주는 상수를 뜻한다. \n",
        "이렇게 구해진 값들을 활성화 함수(계단함수)를 통해서 출력을 얻어낸다.<br/>\n",
        "수식 y={<br/>0 (b+w1x1+w2x2≤0)<br/>1 (b+w1x1+w2x2>0)<br/>}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fm-d8qFseR8A"
      },
      "source": [
        "## [] MLP (Multi Layer Perceptron)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zrm4vmtbZbYN"
      },
      "source": [
        " <img src=\"https://ds-lecture-data.s3.ap-northeast-2.amazonaws.com/etc/note_image/perceptron_TLU.png\" width=\"400\"/>\n",
        "\n",
        "   하지만 기본적인 퍼셉트론으로는 XOR GATE와 같은 구조를 만들 수 없다는 한계점이 있었고 이를 해결하기 위해서 은닉층이 추가된 다층 퍼셉트론이 등장하게 되었다.<br/>\n",
        "  다층 퍼셉트론이란 입력과 출력사이에 사람이 볼 수 없는 계산 과정이 일어나는 은닉층을 추가해서 은닉층의 가중치를 학습한다. <br/> \n",
        "  이러한 Hidden Layer가 2개 이상인 경우를 딥러닝이라고 한다.<br/>\n",
        "  은닉층은 입력을 받고 가중치와 바이어스를 이용해 계산값을 구하는데 계산 결과가 활성함수를 통과하면 값이 넘어가고 그렇지 않으면 값이 넘어가지 않는다.<br/>\n",
        "  이때 사용되는 활성함수는 Sigmoid, Relu, Softmax, 항등함수 등이 있다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UV18eLMweeiQ"
      },
      "source": [
        "## [] Activation Function<br/><br/>\n",
        "\n",
        "신경망 회로에서 한 노드에 대해 입력값을 다음 노드에 보낼지 말지를 결정하는 함수.<br/> 한마디로 입력신호의 총합을 출력신호로 변환하는 함수이다.\n",
        "주로 비선형 함수이다.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ez_DAFuv8TDU"
      },
      "source": [
        "###[] Step\n",
        " <img src=\"https://t1.daumcdn.net/cfile/tistory/99B3CD3359F5F56B36\" width=\"400\"/>\n",
        "\n",
        " 임계인 0보다 작으면 신호를 보내지 않고 0보다 크면 신호를 보내는 계단모양의 함수이다. 미분이 불가능해서 실제로 사용하지는 않는다.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DISVpSwrfKC3"
      },
      "source": [
        "###[] Sigmoid\n",
        " <img src=\"https://t1.daumcdn.net/cfile/tistory/994E183D5B6D2C230A\" width=\"400\"/>\n",
        "\n",
        "0과 1사이의 값을 출력한다.\n",
        "임계값인 0일때 0.5의 신호를 내보내는 특징이 있다.\n",
        "기울기 소실의 문제가 있다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JOvQWfzb8tn8"
      },
      "source": [
        "###[] Relu\n",
        " <img src=\"https://t1.daumcdn.net/cfile/tistory/990E4E3F5B6D2CAE28\" width=\"400\"/>\n",
        "\n",
        " x>0이면 기울기가 1인 직선이고, x<0 이면 함수값이 0이된다.<br/>\n",
        "sigmoid, tanh 함수와 비교시 학습이 훨씬 빨라진다.<br/>\n",
        "연산 비용이 크지않고, 구현이 매우 간단하다.<br/>\n",
        "x<0 인 값들에 대해서는 기울기가 0이기 때문에 뉴런이 죽을 수 있는 단점이 존재한다.<br/>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F_hOjIkC845g"
      },
      "source": [
        "###[] tanh\n",
        " <img src=\"https://t1.daumcdn.net/cfile/tistory/99CDE7385B6D2C2333\" width=\"400\"/>\n",
        "\n",
        " Sigmoid 유사하지만 -1부터 1까지의 출력값을 가진다는게 특징이다. Sigmoid Function에 비해 최적화 과정이 느려지는 문제를 해결했지만 이 함수 역시 미분함수에서 x값이 커질수록 0에 수렴하는 형태로 나타나게 되어 기울기 소실 문제가 발생하게 된다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6gtzGf10TPqS"
      },
      "source": [
        "#N412. Backpropagation\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GLBQII3JiOfV"
      },
      "source": [
        "##[] NN Algorithm\n",
        "\n",
        "신경망 알고리즘 순서 요악<br/>\n",
        "\n",
        "1.학습할 신경망 구조를 선택.<br/>\n",
        "-입력층 유닛의 수 = 특징 수<br/>\n",
        "-출력층 유닛의 수 = 타겟 클래스 수<br/>\n",
        "-은닉층 수, 각 은닉층의 노드 수<br/>\n",
        "2.가중치 랜덤 초기화<br/>\n",
        "3.순방향 전파를 통해 $h_{\\theta}(x^{(i)})$(출력층 y값) 을 모든 입력 $x^{(i)}$에 대해 계산.<br/>\n",
        "4.비용함수를 $J(\\theta)$를 계산.<br/>\n",
        "5.역방향 전파를 통해 편미분 값들 $\\frac{\\delta}{\\delta\\theta_{jk}^{l}}{J(\\theta)}$ 을 계산.<br/>\n",
        "6.경사하강법 (or 다른 최적화 알고리즘)을 역전파와 함께 사용하여 비용함수인 $J(\\theta)$ 를 최소화.<br/>\n",
        "7.어떤 중지 기준을 충족하거나 비용함수를 최소화 할 때까지 단계 2-5를 반복합니다. 2-5를 한 번 진행하는 것을 epoch 또는 iteration이라 말합니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eeqqjs1N1OVp"
      },
      "source": [
        "###-> Train\n",
        "훈련데이터로부터 Weight의 최적값을 자동으로 획득하는 것을 뜻한다. Loss값의 결과를 가장 작게 만드는 것이 중요하다.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oX5B3BH51c6u"
      },
      "source": [
        "###-> Loss Function (비용함수)\n",
        "실제값과 예측값을 가지고 SSE 방법 또는 교차 엔트로피 방법을 이용해서 오차를 구하는 방법이다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k7dDBUu6iVXy"
      },
      "source": [
        "##[] Backpropagation\n",
        "역전파라는 뜻으로 신경망의 가중치들을 어떻게 학습해서 업데이트 할지 결정한다. <br>\n",
        "원래의 Target값과 순전파를 통해 나온 Output간의 Loss를 계산해서 Loss값을 다시 뒤로 전파하면서 노드의 가중치를 갱신하는 알고리즘이다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RWLS-JwY7Vs2"
      },
      "source": [
        "<img src=\"https://www.researchgate.net/profile/Wenqiang_Feng2/publication/331482292/figure/fig13/AS:750825655762952@1556022194488/Gradient-Descent-in-1D.jpg\" alt=\"Gradient Descent in 1D\" width=\"400\"/>\n",
        "\n",
        "Loss를 모든 가중치에 대한 방정식으로 본다면 우리는 Loss를 최소로 만들기 위해 가중치 값을 수정해야한다.<br/> \n",
        "기본 원리는 기울기(신경망에서의 기울기는 Weight에 대한 Lossfunction을 뜻한다)가 낮은 쪽으로 연속적으로 이동시켜 값이 최소가 되는 극점에 (Loss = 0)에 다다르게한다. 이를 **경사하강법**이라고 한다.<br/> \n",
        "이를 위해 오차 Loss를 미분하는 과정이 필요한데 모든 가중치가 Loss에 영향을 주고 있으므로 Loss를 각각의 가중치로 편미분한다.<br/>\n",
        "이때 한번에 미분을 할 수 없기 때문에 Chain Rule을 이용한다.<br/>\n",
        "Chain Rule이란 합성함수(여러함수로 구성된 함수)의 미분에 대한 성질을 말한다. ( 합성함수의 미분은 합성함수를 구성하는 각 함수의 미분의 곱)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AnxsfeCa0Qnp"
      },
      "source": [
        "##[] Optimizer<br/><br/>\n",
        "\n",
        "Optimizer(최적화) : 출력값인 예측값과 실제값의 차이를 Error, Cost, Loss라고 부르고 이를 줄이기 위해서 BP를 하면서 학습한다. 입력값은 고정되어 있기 때문에 예측값을 바꾸기 위해서는 Hidden Layer의 가중치를 변경해야한다.<br/>\n",
        "매개변수(Weight)와 기울기 정보를 받아서 매개변수를 갱신한다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Xx1-ddTOO8T"
      },
      "source": [
        "##->SGD\n",
        "<img src='https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FbqaJKT%2FbtqBsZTgOpx%2FkXZEoiND42AIOCJsWmHrrk%2Fimg.png' width=\"400\"/> <br/><br/>\n",
        "수식<br/>\n",
        "<img src='https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=http%3A%2F%2Fcfile27.uf.tistory.com%2Fimage%2F99240A365B6102EC1FBB0C' width=\"200\"/> <br/>\n",
        "<img src='https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=http%3A%2F%2Fcfile22.uf.tistory.com%2Fimage%2F9938813C5B6103C01FFCC4' width=\"20\"/> : step size (learning rate) <br/>\n",
        "<img src='https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=http%3A%2F%2Fcfile6.uf.tistory.com%2Fimage%2F99C62D495B6103C518AFD8' width=\"20\"/> (기울기)<br/><br/>\n",
        "SGD 확률적 경사 하강법 : weight의 기울기를 구해 기울어진 방향으로 매개변수 값을 갱신하는 일을 반복해서 최적의 값에 접근하는 방법.\n",
        "장점 : 단순하다.\n",
        "단점 : 비등방성 함수 (방향에 따라 기울기가 달라지는 함수)에서는 비 효율적이다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TXAUcdO3Pu8g"
      },
      "source": [
        "##->Momentum\n",
        "<img src='https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FdIhN4F%2FbtqBsGfi7w7%2FIF4eHPErjIs9HZMD5YdAok%2Fimg.png' width=\"400\"/> <br/><br/>\n",
        "\n",
        "Momentum 경사 하강법 : SGD경사 하강법에 관성을 더해주는 것이다. 경사 하강법과 마찬가지로 매번 기울기를 구하지만 가중치 수정 전에 수정 방향을 참고해서 같은 방향으로 일정 비율만 수정되기 하는 방법이다. 즉 관성 효과때문에 SGD와 비교했을때 지그재그로 현상이 줄어든다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lgnvqqJVYwml"
      },
      "source": [
        "##->AdaGrad\n",
        "<img src='https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FEfKgF%2FbtqA5Q2H4kh%2F8KA1ygW2eXPgYsnuSAys11%2Fimg.png' width=\"400\"/> <br/><br/>\n",
        "\n",
        "AdaGrad 경사 하강법 : 신경망 학습에서는 학습률 값이 너무 작으면 학습 시간이 길어지고, 반대로 너무 크면 발산해서 학습이 제대로 이뤄지지 않는다.\n",
        "이러한 학습률을 정하는 효과적인 기술로 학습률 감소 방법이 있다.<br/>\n",
        "처음에는 크게 학습하다가 조금씩 작게 학습하는 방법으로 각각의 매개변수에 맞춤형 값을 적용시킨다.\n",
        "\n",
        "<br/><br/>\n",
        "\n",
        "수식<br/>\n",
        "<img src='https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2Fcdc3nQ%2FbtqBzPoDBvk%2FYuvP6IFP2A0nHUbJIIBAc1%2Fimg.png' width=\"200\"/> <br/><br/>\n",
        "\n",
        "장점 : 학습률을 효과적으로 정할 수 있다.<br/>\n",
        "단점 : 과거의 기울기를 제곱해서 계속 더해가는 것이기 때문에 학습이 진행할수록 갱신 강도가 약해진다. 이를 개선하기 위해 과거의 모든 기울기를 균일하게 더하는 것이 아니라 과거의 기울기는 서서히 잊고 **최신의 기울기의 정보를 크게 반영하는 RMSProp방법이 제안되었다.**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "li0UOXheaoyx"
      },
      "source": [
        "##->Adam\n",
        "<img src='https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2F7qrHU%2FbtqBtYlKN0s%2FAr8dLw2ePBk88jkgCkZajk%2Fimg.png' width=\"400\"/> <br/><br/>\n",
        "\n",
        "Adam경사 하강법 : Momentum의 공이 그릇 바닥을 구르는 듯한 관성의 움직임과 AdaGrad의 매개변수의 원소마다의 맞춤형 값을 적용시킨 방법을 융합한 방법이다.<br/><br/>\n",
        "결과적으로 Momentum과 비슷한 패턴이지만 Momentum보다 흔들림이 적다.<br/><br/>\n",
        "Adam은 하이퍼파라미터를 3개 설정한다. 하나는 지금까지의 학습률(논문에서는 α로 등장), 나머지 두 개는 일차 모멘텀용 계수 β1과 이차 모멘텀용 계수 β2이다. 논문에 따르면 기본 설정값은 β1은0.9, β2는0.999이며, 이 값이면 많은 경우에 좋은 결과를 얻을 수 있다.<br/><br/>\n",
        "Adam은 하이퍼파라미터를 3개 설정한다. <br/>\n",
        "하나는 지금까지의 학습률(논문에서는 α로 등장), 나머지 두 개는 일차 모멘텀용 계수 β1과 이차 모멘텀용 계수 β2이다. 논문에 따르면 기본 설정값은 β1은0.9, β2는0.999이며, 이 값이면 많은 경우에 좋은 결과를 얻을 수 있다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gDBE0nPIbVWD"
      },
      "source": [
        "출처:  [밑바닥부터 시작하는 딥러닝]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h5rldlw3iQZM"
      },
      "source": [
        "##[] Weight initialization<br/><br/>\n",
        "\n",
        "신경망 학습이라는 것은 결국 가중치를 학습하는것이다.<br/>\n",
        "그렇다면 초기의 가중치 값은 어떤 값을 가져야할까를 생각하게 될텐데 이에 대해서 알아보겠다.<br/><br/>\n",
        "\n",
        "오버피팅을 억제하기 위한 테크닉으로 Weight Decay 방법이 있다.<br/>\n",
        "Weight Decay(가중치 감소)를 간단히 말하자면 가중치 매개변수 값이 작아지도록 해서 오버피팅을 방지하는 방법이다.<br/>\n",
        "가중치를 작게 만들고 싶다면 초깃값을 최대한 작은 값으로 설정해야 하는데 이것을 가중치 초기화라고 한다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7GPQAI8XplI6"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x_3zo_jpqMvJ"
      },
      "source": [
        "###[] 가중치 초기화시 주의사항<br/><br/>\n",
        "\n",
        "가중치가 0이거나 같은 값을 가진다면 모든 뉴런의 동일한 출력값을 낸다. 그렇게 되면 뉴런이 하나인 것 처럼 작동한다.<br/>\n",
        "\n",
        "가중치가 너무 작으면 기울기도 매우 작아서 학습이 되지 않는다. 반대로 너무 클경우 Sigmoid에서 가중치 소실이 발생하고 ReLu에서는 dead ReLu(음수여서 0)또는 가중치 폭발 문제가 발생한다.<br/><br/>\n",
        "설명)<br/>\n",
        "<img src = \"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2Fv0wRy%2FbtqBuxhV2pU%2FNH2pb3nEXs1NFYlixaaMOK%2Fimg.png\" width = '800'>\n",
        "<br/><br/>\n",
        "위의 그림은 가중치를 표준편차가 1인 정규분포로 초기화할 때의 각 층의 활성화 값 분포이다.<br/> \n",
        "여기서 sigmoid 함수를 사용하면 출력이 0또는 1에 가까워 질 때 미분값이 0에 가까워 진다.<br/>\n",
        "그래서 데이터가 0과1에 치우쳐서 분포하면 BP의 기울기 값이 점점 작아지다가 사라지는 **기울기 소실문제**가 발생한다.\n",
        "<br/><br/>\n",
        "\n",
        "<img src = \"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2Fbr1t6Z%2FbtqBuaOiO46%2FBWh4nl4a3bgKijzCeGERvk%2Fimg.png\" width = '800'>\n",
        "<br/><br/>\n",
        "\n",
        "위의 그림은 표준편차가 0.01로 한 중규 분표의 활성화값 분포이다.<br/>\n",
        "이때 기울기 소실문제는 발생하지 않지만 활성화 값들이 치우쳐져서 다수의 뉴런이 거의 같은 값을 출력하고 있어 여러 개의 뉴런을 둔 이유가 없어진다.<br/>\n",
        "이를 **표현력 제한 문제**라고 한다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o26F_VFxBDk5"
      },
      "source": [
        "### []가중치 초기화의 방법\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7_I0LH0Drv2B"
      },
      "source": [
        "####->Xavier<br/><br/>\n",
        "sigmoide나 tanh같은 좌우 대칭이라 중앙부근이 선형이라고 볼 수 있는 활성화함수일 때를 전제로,  \n",
        "앞 계층의 노드값이 n개라면 표준편차를 1/√n 인 분포를 사용한다.<br/>\n",
        "앞 층이 노드가 많을 수록 대상 노드의 초깃값으로 설정하는 가중치가 좁게 퍼져나간다.\n",
        "<img src = \"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FDxsQ1%2FbtqBt9V56HB%2FdTtvdY3NL0mkKK2cyH2LKk%2Fimg.png\" width = '600'>\n",
        "<br/><br/>\n",
        "<img src = \"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2Fbz2H6h%2FbtqBuPWXWqx%2F4xmrhfYHENuB37xI3gVkFK%2Fimg.png\" width = '600'>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nePD8sKxxWRl"
      },
      "source": [
        "####->He<br/><br/>\n",
        "ReLu에 특화된 가중치 초기값 ,  \n",
        "앞 계층의 노드값이 n개라면 표준편차를 √(2/n)인 분포를 사용한다.<br/>\n",
        "ReLu는 음의 영역이라 0이라서 더 넓게 분포시키기 위해 2배의 계수가 필요하다고 보면 된다.\n",
        "<img src = \"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FyOfGP%2FbtqBt9IFCzR%2Fg12hWoTAQ7rKWQn5Uu5ZPk%2Fimg.png\" width = '600'>\n",
        "<br/><br/>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k9YpkKW2yzOC"
      },
      "source": [
        "###[] Batch Normalization<br/><br/>\n",
        "\n",
        "Batch Normalization(배치 정규화)라는 것은 학습 시 미니배치를 단위로 정규화해서 <br/> 각 층이 활성화를 적당히 분포되도록 조정 하는 것이다.  <br/>\n",
        "장점 : 학습 진도가 빨라지고, 가중치 초기값에 크게 의존하지 않는다.<br/>\n",
        "\n",
        "<img src = \"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FcFYkLE%2FbtqEcUnlXKy%2FZbGZNjObjo2gL2xss8zYzk%2Fimg.png\" width = '500'>\n",
        "\n",
        "간단히 말하자면 미니배치의 평균과 분산을 이용해 정규화를 구하고 scale 및 shift 를 감마(γ) 값, 베타(β) 값을 통해 수행한다. 감마와 베타 값은 Backpropagation을 통해서 학습이 가능한 변수이다.\n",
        "<br/><br/><br/>\n",
        "<img src = \"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2F4RkdF%2FbtqEdkTEWnl%2FCmZoRyLKCa9LhrGsPgJUa0%2Fimg.png\" width = '500'>\n",
        "\n",
        "정규화 된 값을 활성화 함수의 입력으로 사용하고, 최종 출력 값을 다음 레이어의 입력으로 사용한다.<br/>\n",
        "기존 output = g(Z), Z = WX + b 식은 output = g(BN(Z)), Z = WX + b 로 변경된다.<br/>\n",
        "데이터를 계속 정규화 하게 되면 활성화 함수의 비선형 같은 성질을 잃게 되는데 이러한 문제를 완화하기 위해 입실론(θ)이라는 값을 넣어 계산시 0으로 나눠지는 문제가 발생하는 것을 방지한다.<br/><br/>\n",
        "\n",
        "- 단순하게 평균과 분산을 구하는 것이 아니라 감마(Scale), 베타(Shift) 를 통한 변환을 통해 비선형 성질을 유지 하면서 학습 될 수 있게 해준다.\n",
        "배치 정규화가 신경망 레이어의 중간 중간에 위치하게 되어 학습을 통해 감마, 베타를 구할 수 있다.<br/>\n",
        "- Internal Covariate Shift 문제로 인해 신경망이 깊어질 경우 학습이 어려웠던 문제점을 해결한다.<br/>\n",
        "- 기존 방법에서 learning rate 를 높게 잡을 경우 gradient 가 vanish/explode 하거나 local minima 에 빠지는 경향이 있는데, 배치 정규화를 사용할 경우 파라미터의 scale영향을 받지 않는다. <br/>그 때문에 gradient의 스케일이나 초기값에 대한 의존성이 줄어 Large Learning Rate 를 설정할 수 있기 떄문에 결과적으로 빠른 학습 가능하다.<br/>\n",
        "- regularization 효과가 있기 때문에 dropout 등의 기법을 사용하지 않아도 됨 (효과가 같기 때문)\n",
        "\n",
        "\n",
        "Refer:  [Enough is not enough]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o8WY_cONTQh3"
      },
      "source": [
        "# N413. 신경망 프레임워크와 학습규제(regularization) 전략\n",
        "오버피팅 문제 발생을 억제하기 위한 학습규제 전략<br/>\n",
        "오버피팅이 주로 일어나는 상황 : <br/>\n",
        "1) feature가 많고 표현력이 높은 모델<br/>\n",
        "2) 훈련 데이터가 적을 경우<br/><br/>\n",
        "\n",
        "오버피팅을 방지하기 위한 전략들을 소개한다.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I_QJIDG30pzM"
      },
      "source": [
        "##[] EarlyStopping<br/><br/>\n",
        "\n",
        "<img src = \"https://gblobscdn.gitbook.com/assets%2F-LsGrpMiOeoMSFYK0VJQ%2F-LvIyf52PyN5J9tSk7jI%2F-LvIzziN3xOLT7JDtmUZ%2Fearlystopping.png?alt=media&token=6c4f82f2-e3ba-461d-9dc8-c739087c560a\" width = '400'><br/>\n",
        "\n",
        "모델을 더 이상 학습을 못할 경우(loss, metric등의 개선이 없을 경우), 학습 도중 미리 학습을 종료시키는 콜백함수이다. 다른 학습규제 방법과 함께 사용한다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HtLattlL0skk"
      },
      "source": [
        "##[] Weight Decay<br/><br/>\n",
        "Weight Decay(가중치 감소) : 학습 과정에서 큰 가중치에 대해서는 그에 상응하는 큰 페널티를 부과해서 오버피팅을 억제하는 방법.<br/>\n",
        "가중치의 제곱 Norm을 손실함수에 더해 가중치가 커지는 것을 억제한다.<br/>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BE4rcJfy3_aO"
      },
      "source": [
        "###-> L1, L2 <br/>\n",
        "$L1 Norm =$ 가중치 절대의값의 합 ,  $|W1| + |W2| |W3| + ... + |Wn|$<br/><br/>\n",
        "$L2 Norm =  √(W1^2 + W2^2+ W3^2 + ... + W1^2)$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GKpmHJR90uL7"
      },
      "source": [
        "##[] Drop Out<br/><br/>\n",
        "\n",
        "신경망이 복잡해지면 Weight Decay만으로 대응하기 힘들어진다.<br/>\n",
        "Drop Out은 신경망이 복잡해질때 대응하기 위한 방법으로 뉴런을 임의로 삭제시키는 학습법이다. -> 앙상블 모델과 유사하다.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LrmkB1ZM0xK9"
      },
      "source": [
        "##[] Learning Rate"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MDMY6_-aye1k"
      },
      "source": [
        "#####->step<br/><br/>\n",
        "<img src = \"https://media.vlpt.us/images/good159897/post/76d5e6f1-72b2-4746-a06c-47c757c8e4f4/Learning_rate_decay_Step.PNG\" width = \"800\"><br/>\n",
        "\n",
        "설명 : 특정 epoch를 기준으로 lr(learning rate)를 감소시키는 것을 말한다.<br/>\n",
        "위의 예제에서는 30 epoch마다 0.1의 비율로 감소 시켰다.<br/>\n",
        "단점 : loss의 방향성은 맞지만 연속적이지 않다. \n",
        "또한 몇 epoch마다 감소시킬지 정해야한다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sKfSlC1e1gV2"
      },
      "source": [
        "####->Constant<br/><br/>\n",
        "<img src = \"https://media.vlpt.us/images/good159897/post/6acaecfe-54cd-43b8-99a8-1e915972064a/Learning_rate_decay_Constant.PNG\" width = \"800\"><br/>\n",
        "\n",
        "설명 : lr(learning rate)를 상수값으로 지정하는 방법이다.<br/>\n",
        "다른 lr을 사용하면 결과가 더 좋아질 수는 있지만 가능한한 빨리 작동시키고자 할때는 lr을 일반적인 상수로 둘 수 있다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VRlWios12GN4"
      },
      "source": [
        "#N414. 신경망과 학습에 관련된 파라미터 튜닝 (HyperTune)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WIYl6Wim-uVL"
      },
      "source": [
        "####[]전처리<br>\n",
        "->입력 데이터 정규화 (Normalizing)<br/>\n",
        "->학습/검증 데이터 분류<br/>\n",
        "->인코딩(Word2Vec)<br/>\n",
        "->Batch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aZgwMI_9_HRB"
      },
      "source": [
        "###[]하이퍼 파라미터 튜닝 방식<br>\n",
        "->Babysitting : 파라미터 튜닝 값을 수동으로 입력하는 것<br/><br/>\n",
        "\n",
        "->Grid Search : 실험할 파라미터 튜닝값의 조합을 자동으로 돌리는 방식, 파라미터 값을 잘못 조정하면 파라미터 탐색 시간이 너무 길어진다. <br/>\n",
        "Grid Search를 사용할 계획이라면, 여러 하이퍼 파라미터의 조합을 찾는 데 사용하지 말고 오직 하나의 파라미터의 최적값을 찾는데 활용하는것이 바람직하다. <br/><br/>\n",
        "\n",
        "-> Random Search : 지정된 범위내에서 무작위로 선정한 조건으로 모델을 돌려서 최적의 구성을 조합한다. 상대적으로 중요하다고 생각되는 파라미터에 대해 탐색을 더 하고, 덜 중요한 하이퍼파라미터에 대해서는 실험을 덜 진행한다. <br/>\n",
        "장점으로 시간이 덜 걸리지만 단점으로 시간이 덜 걸리는 만큼 완벽한 하이퍼 파라미터를 찾지는 못한다.<br/><br/>\n",
        "->Bayesian Methods :  실험자가 결과를 보고 추후 탐색에 그 결과에서 얻은 정보를 반영하는 것\" "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fNQYeQqmBI9l"
      },
      "source": [
        "###[]튜닝 파라미터"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OjjFJUowBVW2"
      },
      "source": [
        "####->batch_size\n",
        "설명 : 한번에 몇개의 관측치를 보게 되는지를 결정하는 파라미터<BR/>\n",
        "배치사이즈를 잘 선택하면 일반화가 잘된다고 한다.<BR/>\n",
        "너무 큰 배치 크기를 고르게 되면 한번에 모든 데이터에 대한 Loss를 계산해야 하는 문제가 발생하고 학습 속도가 빠르기 때문에 주어진 epoch 안에 가중치를 충분히 업데이트 할 만큼의 iteration이 나오지 않는다.<BR/>\n",
        "반대로 너무 작은 배치 크기를 고르게 되면 학습시간이 오래 걸리고 예측값에 노이즈가 많이 걸린다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6jfUkcMGBbEj"
      },
      "source": [
        "####->optimization algorithms\n",
        "optimizer를 어느것으로 선택하느냐에 따라 결과가 달라진다. 또한 optimizer에 따라서 lr이나 momentum 튜닝이 필요할 수도 있다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1L-GejfcBa91"
      },
      "source": [
        "####->learning rate<br/>\n",
        "Learning Rate은 경사하강법 기반의 optimizer 선택을 위한 하이퍼 파라미터.<br> 기본 값 : 0.01<br>\n",
        "lr 너무 높은 경우에는 모델이 발산, 반대로 너무 낮게 설정하면 모델이 수렴.\n",
        "보통은 크기순으로 learning rate을 튜닝합니다 <br>([.001, .01, .1, .2, .3, .5])\n",
        "->0.5보다 높이 잡는 것은 추천하지 않음."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ItY7nsxgBa3s"
      },
      "source": [
        "####->momentum\n",
        "설명 : optimizer가 최솟값을 overshooting 하게 결정하는 속성으로 지역 최소점(local minima)에서 탈출하도록 시도하는 것입니다.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NjHwO2Y5Bawr"
      },
      "source": [
        "####->activation functions<br/>\n",
        "보통은 은닉층에는 ReLU를 사용하고 출력층에는 Sigmoid (이진 분류)나 Softmax (다중분류)를 사용하지만 모델에 따라서 sigmoid, tanh 등 다른 활성함수들을 시도해볼 수 있다.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kaRMfFdpBan-"
      },
      "source": [
        "####->Dropout & Weight Constraint<br/>\n",
        "Weight Constraint은 Dropout과 함께 쓰는 두번째 규제 파라미터입니다.<br/>\n",
        "튜닝을 할 때는 이 두개값 모두 튜닝해야합니다.<br/>\n",
        "드롭아웃을 어느 layer (visible vs. hidden)에 적용하는지에 따라 다른 효과를 불러올 수 있습니다.<br/>\n",
        "은닉층에 드롭아웃을 썼을 때 엄청난 효과를 부를 때도 있지만, 반대로 아무런 일도 일어나지 않을 수 있는 것 입니다.<br/>\n",
        "사용하고 있는 모델이 과적합이나 일반화 문제가 있지 않다면 굳이 쓸 필요는 없습니다. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xBtwm0_JBaRQ"
      },
      "source": [
        "####->hidden layer의 neuron 갯수<br/>\n",
        "많은 노드와 레이어는 학습 시간을 늘리게 되고 모델이 과적합할 확률을 높입니다.<br/>\n",
        "신경망이 커질수록 드롭아웃 규제나 다른 규제 방법으로 이러한 가능성들에 대비 해야한다.<br/>\n"
      ]
    }
  ]
}