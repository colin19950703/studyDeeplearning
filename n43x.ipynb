{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled3.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dGyE-2QLeBRC"
      },
      "source": [
        "# N431. Convolutional Neural Networks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QDBbCb7KgxRI"
      },
      "source": [
        "용어 설명\n",
        "\n",
        "Convolution : 합성곱, 이미지에 필터 마스크를 적용한다고 생각하면 된다.\n",
        "\n",
        "Filter: 가중치 (weights parameters)의 집합으로 이루어져 가장 작은 특징을 잡아내는 창. 필터 마스크라고 생각하면 된다.\n",
        "\n",
        "Stride: 필터(filter)를 얼만큼씩 움직이며 이미지를 볼 지 결정하는 수 (예) \n",
        "Stride가 1이면 한칸씩 이동하며, 누락없이 모든것을 본다면, stride가 2 이면 한칸씩 건너뛰면서 Filter를 적용하게 되고, 띈 만큼 다음 레이어의 데이터의 수가 줄어든다.\n",
        "\n",
        "Padding: Zeros(또는 다른 값)을 이미지의 외각(가장자리)에 배치하여 conv를 할 때 원래 이미지와 같은 데이터의 수를 갖을 수 있도록 도와줌 (Stride = 1일 때)\n",
        "\n",
        "Pooling : 풀링 레이어를 사용하여 피처맵의 차원을 줄인다. 보통의 경우 컨볼루션을 적용한 이후 레이어를 풀링하여 점점 더 작은 피쳐맵를 얻습니다. 이렇게 줄어든 피쳐들을 이용하여 ANN형태의 신경망에 넣어 Classification or regression을 수행하게 된다.\n",
        "\n",
        "Feature map(Activation map) : Input 이미지와 Filter 이미지의 Conv연산을 통해 나온 결과로 이밎지의 특징을 나타내는 역할을 한다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fFS0b39g37W3"
      },
      "source": [
        "###[]Convolution Layer<br>\n",
        "<img src = \"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Ft1.daumcdn.net%2Fcfile%2Ftistory%2F997FFF335B61925D04\" width = '800'><br>\n",
        "Convolution layer에서의 input값은 fully-connected layer와는 다르게 원형을 보존한 상태로 둔다(공간영역을 훼손하지 않는다).<br><br>\n",
        "\n",
        "1) filter의 깊이(채널)는 input의 깊이(채널)와 같아야 하므로 3이다.<br><br>\n",
        "2) input 이미지에 필터마스크를 적용하는 conv 연산을 진행한다.<br><br>\n",
        "->이때 사이즈가 계속 줄어든다면 사진의 공간정보가 훼손된다는 취지에 좋지 못하기 때문에 Padding을 통해서 Output Size를 32x32로 고정할 수 있다.<br><br>\n",
        "->padding을 하지 않을 경우 stride가 1이라면(마스크가 한칸씩 이동한다면) 28x28x1이라는 output(activation map)이 나오게 된다. 아래의 공식 참조<br>\n",
        "<img src = \"https://miro.medium.com/max/660/1*V5ZIZg7cGHLASKbnRbKBJQ.png\" width = '200'><br><br>\n",
        "\n",
        "<img src = \"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Ft1.daumcdn.net%2Fcfile%2Ftistory%2F99FD46335B61925F0A\" width = '800'><br>\n",
        "\n",
        "\n",
        "<img src = \"https://taewanmerepo.github.io/2018/01/cnn/conv2.jpg\" width = '400'><br>\n",
        "3)CNN에서는 1개의 필터만을 사용하지 않는다 예를 들어서 6개의 필터를 사용하면 6개의 feature map(actiavtion map)이 나온다.<br>\n",
        "->입력 데이터의 채널 수와 상관없이 필터 별로 1개의 feature map(activation map)이 만들어 진다.<br>\n",
        "->하나의 Convolution Layer에 크기가 같은 여러 개의 필터를 적용할 수 있습니다.<br> 이 경우에 Feature Map(activation map)에는 필터 갯수 만큼의 채널이 만들어집니다.<br> 입력데이터에 적용한 필터의 개수는 출력 데이터인 Feature Map(activation map)의 채널이 됩니다.<br>아래의 사진, input에 적용한 필터 수 = 192, feature map 채널수 192개<br>\n",
        "\n",
        "<img src = \"https://ds-lecture-data.s3.ap-northeast-2.amazonaws.com/etc/note431/CNN3.png\" width = '800'><br><br>\n",
        "\n",
        "4) 이러한 과정을 반복하는 것이 CNN이다.\n",
        "-> 위의 28x28x6의 이미지에 필터를 씌우려면 필터의 채널수는 적어도 6이여야 할 것이다. \n",
        "->예를 들어 28x28x6의 이미지에 5x5x6의 필터 10개가 들어간다면 다음 activation map의 크기는 24x24x10일 것이다.\n",
        "-> 필터 한개에 activation map 한 겹이 쌓인다고 생각하면 된다.<br>\n",
        "<img src = \"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Ft1.daumcdn.net%2Fcfile%2Ftistory%2F99C1033F5B61926129\n",
        "\" width = '800'><br><br>\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GEX2sHaW1lDI"
      },
      "source": [
        "###[]FC(Fully Connected)\n",
        "<img src = \"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Ft1.daumcdn.net%2Fcfile%2Ftistory%2F991CF9415B61925C1A\" width = \"800\">\n",
        "<br/>\n",
        "convolution 하고, ReLU도 해주고, Pooling도 하고 이 과정들을 반복하면서 나온 가장 마지막 activation map들의 pooling까지 끝났을 때, 우리는 그 이미지들을 FC Layer에 집어넣습니다.\n",
        "\n",
        "<br/>32x32x3 (가로 32, 세로 32, RGB)인 이미지를 10개의 클래스로 분류하는 문제.\n",
        "\n",
        "\n",
        "1) 32x32x3을 입력할 수 있게 3072x1사이즈로 만든다. (input size = 32x32x3 = 3072x1)<br>\n",
        "2)$W_x$값들은 (클래스 개수인) 10 * 3072로 만든다.\n",
        "input과 Weight를 곱하여 10개의 output 값들을 만들어 내는 layer가 바로 Fully connected layer였습니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BtvLkES3Ltyy"
      },
      "source": [
        "###[]SC(Skipped Connection)\n",
        "<img src = \"https://neurohive.io/wp-content/uploads/2019/01/resnet-e1548261477164.png\" width =\"400\"> <br/>\n",
        "일반적인 신경망 모델 학습 시 모델의 층이 깊어질수록 학습 결과가 좋을 수 있다고 알려져 있습니다. <br/>\n",
        "하지만 층을 너무 깊이 쌓거나 노드 수를 너무 크게 증가시키면 입력 정보가 여러 층을 거치면서 이전 층에 대한 정보 손실이 발생할 수 있고 가중치가 잘못된 방향으로 갱신되는 문제가 발생할 수 있습니다. <br/>\n",
        "그래서 이전 층의 정보를 이용하기 위해 이전 층의 정보를 연결하는 잔차 연결(skip connection)을 적용합니다. <br/>\n",
        "잔차 연결이란 입력값 x를 타깃값 y로 매핑(mapping)하는 함수 H(x)를 구하는 과정에서 y를 x의 대변으로 보고 H(x)-x를 찾아 나가는 과정을 학습하는 것으로 정의합니다. <br/>\n",
        "즉, 네트워크의 입력과 출력이 더해진 것이 다음 층의 입력으로 사용됩니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yK_R4_alIv2c"
      },
      "source": [
        "###[]Transfer Learning (전이학습)\n",
        "\n",
        "<img src = \"https://miro.medium.com/max/1000/1*LUFUl_8fqS97nUzpcFjgWw.png\" width = \"800\"><br/>\n",
        "\n",
        "기존(내 목적과는 다른) 데이터로 학습된 네트워크를 재사용 가능하도록하는 라이브러리\n",
        "\n",
        "1)이전에 학습한 모델에서 파라미터를 포함한 레이어를 가져옵니다.<br/>\n",
        "향후 교육 과정 중에 포함된 정보가 손상되지 않도록 해당 정보를 동결(freeze, 가중치를 업데이트 하지 않음)합니다.<br/>\n",
        "2)동결된 층 위에 새로운 층 (학습 가능한 층)을 더합니다.<br/>\n",
        "3)출력층(output)의 수를 조절하여 새로운 데이터셋에서 원하는 예측방법(분류, 회귀 등)으로 전환하는 방법을 배울 수 있게됩니다.<br/>\n",
        "4)새로운 데이터셋에서 새로 추가한 계층만을 학습합니다.<br/>\n",
        "만약 기존 레이어를 동결하지 않으면, 학습된 레이어에서 가져온 weight까지 학습하게 됩니다.<br/>\n",
        "위 경우 학습할 것이 많아지므로 시간이 오래걸립니다.<br/>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rmPkJBpxeCNo"
      },
      "source": [
        "#N432. Image Segmentation & Data Augmentation<br/>\n",
        "이미지 분할(Image Segmentation) : 기존의 이미지 하나를 전체적으로 분류하는 classification이 아니라 이미지 내에서 object마다의 영역별로 label을 붙여 분할하고 학습하는 알고리즘\n",
        "<img src = \"https://chadrick-kwag.net/wp-content/uploads/2020/09/fwfewfewfewq.png\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_ipxEQTkOYX3"
      },
      "source": [
        "### [] U-Net\n",
        "<img src = \"https://lmb.informatik.uni-freiburg.de/people/ronneber/u-net/u-net-architecture.png\" width = \"800\"><br>\n",
        "\n",
        "이미지의 전반적인 컨텍스트 정보를 얻기 위한 네트워크 + 정확한 지역화(localizataion)을 위한 네트워크\n",
        "\n",
        "Context: 이웃한 픽셀 간의 정보, 이미지의 일부를 보고 이미지의 문맥 파악\n",
        "\n",
        "<img src = \"https://media.vlpt.us/images/guide333/post/6b48a343-40ce-4537-8232-30df3ef37a8c/Screenshot%20from%202021-03-16%2023-28-25.png\" width = \"800\"><br>\n",
        "\n",
        "<img src = \"https://media.vlpt.us/images/guide333/post/e70c9e4d-5a64-4c09-94b8-93f5aaf506d1/Screenshot%20from%202021-03-16%2023-30-32.png\" width = \"800\"><br>\n",
        "<img src = \"https://media.vlpt.us/images/guide333/post/69e9cfbc-3db4-421e-b04a-e44b5f2c7ee9/Screenshot%20from%202021-03-16%2023-31-28.png\" width = \"800\"><br>\n",
        "<img src = \"https://media.vlpt.us/images/guide333/post/0def89a9-532e-4933-bebe-16e0176391a0/Screenshot%20from%202021-03-16%2023-18-30.png\" width = \"800\"><br>\n",
        "\n",
        "CNN 네트워크의 얕은 층은 국소적이고 세밀한 부분의 특징을 추출하고 깊은 층은 전반적이고 추상적인 특징을 추출한다. <br>\n",
        "서로 다른 특징을 추출하는 이 두 층을 결합해 주어서 국소적인 정보와 전역적인 정보를 모두 포함할 수 있게 한다.<br>\n",
        "장점 : <br>\n",
        "적은 양의 학습 데이터로도 Data Augmentation을 활용해 여러 Biomedical Image Segmentation 문제에서 우수한 성능을 보인다.<br>\n",
        "컨텍스트 정보를 잘 사용하면서도 정확히 지역화한다.<br>\n",
        "End-to-End 구조로 속도가 빠름<br>\n",
        "->속도가 빠른 이유: 검증이 끝난 곳은 건너뛰고 다음 Patch부터 새 검증을 하기 때문\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cKa1Yd6MOzMj"
      },
      "source": [
        "###[] 데이터 증강 (Data Augmentation)<br>\n",
        "학습 데이터가 부족한 상황에서 Rotaion, ReScaling, Crop, Zoom, Brightness변환등을 이용해서 데이터의 양을 늘릴 수 있다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8ZfI7boyeCfi"
      },
      "source": [
        "#N433. Autoencoders (AE)\n",
        "오토인코더(Autoencoders)는 입력데이터 자체를 레이블로 활용하는 학습방식 \n",
        "(별도의 레이블이 필요하지 않는 비지도학습)<br>\n",
        "\n",
        "데이터 코딩(encoding, decoding)을 위해서 원하는 차원만 할당해주면, 자동으로 학습하여 원하는 형태로 데이터의 차원을 축소해주는 신경망의 한 어플리케이션이다.<br>\n",
        "\n",
        "학습 과정에서는 인코딩 모델(파라미터)과 디코딩 모델(파라미터)가 동시에 학습이 되지만, 이를 각각의 모델로 구분하여 사용할 수 있다.<br>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UImn0b8zeBYc"
      },
      "source": [
        "#N434.Generative Adversarial Networks, GAN"
      ]
    }
  ]
}